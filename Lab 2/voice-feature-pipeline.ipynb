{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ffmpeg and other dependencies\n",
    "%add-apt-repository -y ppa:jonathonf/ffmpeg-4\n",
    "%apt update\n",
    "%apt install -y ffmpeg\n",
    "%pip install datasets>=2.6.1\n",
    "%pip install git+https://github.com/huggingface/transformers\n",
    "%pip install librosa\n",
    "%pip install evaluate>=0.30\n",
    "%pip install jiwer\n",
    "%pip install gradio\n",
    "%pip install hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup HuggingFace and Hopsworks\n",
    "from huggingface_hub import notebook_login\n",
    "import hopsworks\n",
    "\n",
    "notebook_login()\n",
    "project = hopsworks.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and initialize dataset\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"train+validation\", use_auth_token=True)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"test\", use_auth_token=True)\n",
    "\n",
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataset to match the format of the pretrained model\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperProcessor\n",
    "from datasets import Audio\n",
    "\n",
    "# Preparing function to transform dataset\n",
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "# Initialize transformsers\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Swedish\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Swedish\", task=\"transcribe\")\n",
    "\n",
    "# Transform dataset\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to disk\n",
    "import os\n",
    "\n",
    "common_voice.save_to_disk(\"common_voice\")\n",
    "cc = DatasetDict.load_from_disk(\"common_voice\")\n",
    "print(os.getcwd())\n",
    "print(os.listdir(\"./common_voice/\"))\n",
    "print(os.listdir(\"./common_voice/train\"))\n",
    "print(os.listdir(\"./common_voice/test\"))\n",
    "\n",
    "# This does not work\n",
    "def get_dir_size(path='/common_voice/train'):\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total\n",
    "    \n",
    "#sz = get_dir_size(path=\"/root/.cache/common_voice/\")\n",
    "#print(sz)\n",
    "\n",
    "# Save your dataset to google drive\n",
    "# This is untested code - just a suggestion\n",
    "common_voice.save_to_disk(F\"/content/gdrive/My Drive/common_voice/\")\n",
    "cc2 = DatasetDict.load_from_disk(\"/content/gdrive/My Drive/common_voice\")\n",
    "\n",
    "# Upload dataset (.arrow) to Hopsworks\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "path1 = dataset_api.upload(\n",
    "    local_path = \"./common_voice/dataset_dict.json\", \n",
    "    upload_path = \"/Projects/nathanotal/Voice/\", overwrite=True)\n",
    "\n",
    "path2 = dataset_api.upload(\n",
    "    local_path = \"./common_voice/train/state.json\", \n",
    "    upload_path = \"/Projects/nathanotal/Voice/train/\")\n",
    "\n",
    "path3 = dataset_api.upload(\n",
    "    local_path = \"./common_voice/test/state.json\", \n",
    "    upload_path = \"/Projects/nathanotal/Voice/test/\")\n",
    "\n",
    "path4 = dataset_api.upload(\n",
    "    local_path = \"./common_voice/test/dataset.arrow\", \n",
    "    upload_path = \"/Projects/nathanotal/Voice/test/\")\n",
    "\n",
    "# Extra\n",
    "path5 = dataset_api.upload(\n",
    "    local_path = \"./common_voice/train/dataset.arrow\", \n",
    "    upload_path = \"/Projects/nathanotal/Voice/train/\")\n",
    "\n",
    "# Print the paths to the uploaded files\n",
    "print(path1, path2, path3, path4, path5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73777277ffe1eb9718db2f7ff3a495dee19e3d7886774dea57bf006966fae6c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
