{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzVD9-BgEGCX"
      },
      "outputs": [],
      "source": [
        "# Install ffmpeg and other dependencies\n",
        "!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n",
        "!apt update\n",
        "!apt install -y ffmpeg\n",
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install librosa\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install gradio\n",
        "!pip install hopsworks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il9eh2zBEGCb"
      },
      "outputs": [],
      "source": [
        "# Setup HuggingFace and Hopsworks\n",
        "from huggingface_hub import notebook_login\n",
        "import hopsworks\n",
        "\n",
        "# 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\n",
        "notebook_login()\n",
        "# 993jhbhPecCt6fS5.gvlZik4edWefbGbguZVwrES34rJrBQuaUBpHcJapmRlD6UseqKirncAUSNBOCTBq\n",
        "project = hopsworks.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uzTpRMOEGCd"
      },
      "outputs": [],
      "source": [
        "# Download and initialize dataset\n",
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"train+validation\", use_auth_token=True)\n",
        "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"test\", use_auth_token=True)\n",
        "\n",
        "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from datasets import load_dataset, DatasetDict\n",
        "#\n",
        "#dataset = load_dataset('csv', data_files='combinedV1.csv')\n",
        "#train_dataset, validation_dataset= dataset['train'].train_test_split(test_size=0.1).values()\n",
        "#common_voice = DatasetDict({'train': train_dataset, 'val': validation_dataset})\n",
        "#\n",
        "# load and resample audio data from 48 to 16kHz\n",
        "#    # audio = batch[\"audio\"]\n",
        "#    print(batch)\n",
        "#    au = batch.get('audio')\n",
        "#    # compute log-Mel input features from input audio array \n",
        "#    batch[\"input_features\"] = feature_extractor(au, sampling_rate=16000).input_features[0]\n",
        "#\n",
        "#    # encode target text to label ids \n",
        "#    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids # sentence\n",
        "#    return batch"
      ],
      "metadata": {
        "id": "PD2KnYkNQSRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw9j4ulcEGCf"
      },
      "outputs": [],
      "source": [
        "# Transform dataset to match the format of the pretrained model\n",
        "from transformers import WhisperFeatureExtractor\n",
        "from transformers import WhisperTokenizer\n",
        "from transformers import WhisperProcessor\n",
        "from datasets import Audio\n",
        "\n",
        "# Preparing function to transform dataset\n",
        "def prepare_dataset(batch):\n",
        "    # load and resample audio data from 48 to 16kHz\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # compute log-Mel input features from input audio array \n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # encode target text to label ids \n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "# Initialize transformsers\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Swedish\", task=\"transcribe\")\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Swedish\", task=\"transcribe\")\n",
        "\n",
        "# Transform dataset\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ljGXm4DEGCg"
      },
      "outputs": [],
      "source": [
        "# Save the dataset to disk\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "common_voice.save_to_disk(\"common_voice\")\n",
        "cc = DatasetDict.load_from_disk(\"common_voice\")\n",
        "print(os.getcwd())\n",
        "print(os.listdir(\"./common_voice/\"))\n",
        "print(os.listdir(\"./common_voice/train\"))\n",
        "print(os.listdir(\"./common_voice/test\"))\n",
        "\n",
        "# This does not work\n",
        "def get_dir_size(path='/common_voice/train'):\n",
        "    total = 0\n",
        "    with os.scandir(path) as it:\n",
        "        for entry in it:\n",
        "            if entry.is_file():\n",
        "                total += entry.stat().st_size\n",
        "            elif entry.is_dir():\n",
        "                total += get_dir_size(entry.path)\n",
        "    return total\n",
        "    \n",
        "#sz = get_dir_size(path=\"/root/.cache/common_voice/\")\n",
        "#print(sz)\n",
        "\"\"\"\n",
        "\n",
        "# Save your dataset to google drive\n",
        "# common_voice.save_to_disk(F\"/content/gdrive/My Drive/common_voice/\")\n",
        "# cc2 = DatasetDict.load_from_disk(\"/content/gdrive/My Drive/common_voice\")\n",
        "\n",
        "# Upload dataset (.arrow) to Hopsworks\n",
        "# dataset_api = project.get_dataset_api()\n",
        "\n",
        "# Upload Dataset Dict\n",
        "path1 = dataset_api.upload(\n",
        "    local_path = \"./common_voice/dataset_dict.json\", \n",
        "    upload_path = \"/Projects/nathanotal/Voice/\", overwrite=True)\n",
        "\n",
        "# Upload train state\n",
        "path2 = dataset_api.upload(\n",
        "    local_path = \"./common_voice/train/state.json\", \n",
        "    upload_path = \"/Projects/nathanotal/Voice/train/\", overwrite=True)\n",
        "\n",
        "# Upload train info\n",
        "path3 = dataset_api.upload(\n",
        "    local_path = \"./common_voice/train/dataset_info.json\", \n",
        "    upload_path = \"/Projects/nathanotal/Voice/train/\", overwrite=True)\n",
        "\n",
        "# Upload test state\n",
        "path4 = dataset_api.upload(\n",
        "    local_path = \"/content/gdrive/My Drive/common_voice/test/state.json\", \n",
        "    upload_path = \"/Projects/nathanotal/Voice/test/\", overwrite=True)\n",
        "\n",
        "# Upload test info\n",
        "path5 = dataset_api.upload(\n",
        "    local_path = \"/content/gdrive/My Drive/common_voice/test/dataset_info.json\", \n",
        "    upload_path = \"/Projects/nathanotal/Voice/test/\", overwrite=True)\n",
        "\n",
        "# Upload test data\n",
        "path6 = dataset_api.upload(\n",
        "    local_path = \"/content/gdrive/My Drive/common_voice/test/dataset.arrow\", \n",
        "    upload_path = \"/Projects/nathanotal/Voice/test/\", overwrite=True)\n",
        "\n",
        "# # Upload train data\n",
        "path7 = dataset_api.upload(\n",
        "    local_path = \"./common_voice/train/dataset.arrow\", \n",
        "    upload_path = \"/Projects/nathanotal/Voice/train/\", overwrite=True)\n",
        "\n",
        "# Print the paths to the uploaded files\n",
        "print(path1, path2, path3, path4, path5, path6, path7)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "73777277ffe1eb9718db2f7ff3a495dee19e3d7886774dea57bf006966fae6c4"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}